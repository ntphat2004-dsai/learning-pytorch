{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNv1bnl/BjKz8ME6GRfPIT+"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["**What is going modular?**\n","\n","Going modular involves turning notebook code (from a Jupyter Notebook or Google Colab notebook) into a series of different Python scripts that offer similar functionality.\n","\n","For example, we could turn our notebook code from a series of cells into the following Python files:\n","\n","1/ `data_setup.py` - a file to prepare and download data if needed.\n","\n","2/ `engine.py` - a file containing various training functions.\n","\n","3/ `model_builder.py` or `model.py` - a file to create a PyTorch model.\n","\n","4/ `train.py` - a file to leverage all other files and train a target PyTorch model.\n","\n","5/ `utils.py` - a file dedicated to helpful utility functions.\n","\n",">**Note:** The naming and layout of the above files will depend on your use case and code requirements. Python scripts are as general as individual notebook cells, meaning, you could create one for almost any kind of functionality.\n","\n","**Example**\n","\n","For example, you might be instructed to run code like the following in a terminal/command line to train a model:\n","\n","`python train.py --model MODEL_NAME --batch_size BATCH_SIZE --lr LEARNING_RATE --num_epochs NUM_EPOCHS`\n","\n","In this case, train.py is the target Python script, it'll likely contain functions to train a PyTorch model.\n","\n","And --model, --batch_size, --lr and --num_epochs are known as **argument flags**.\n","\n","You can set these to whatever values you like and if they're compatible with train.py, they'll work, if not, they'll error.\n","\n","For example, let's say we wanted to train our **TinyVGG model** from notebook 04 for **10 epochs** with a **batch size of 32** and a **learning rate of 0.001**:\n","\n","`python train.py --model tinyvgg --batch_size 32 --lr 0.001 --num_epochs 10`\n"],"metadata":{"id":"B38toqm50R7p"}},{"cell_type":"markdown","source":["In this session, we want to create our directiory like this:\n","\n","    data/\n","      pizza_steak_sushi/\n","        train/\n","          pizza/\n","            train_image_01.jpeg\n","            train_image_02.jpeg\n","            ...\n","          steak/\n","          sushi/\n","        test/\n","          pizza/\n","            test_image_01.jpeg\n","            test_image_02.jpeg\n","            ...\n","          steak/\n","          sushi/\n","    going_modular/\n","      data_setup.py\n","      engine.py\n","      model_builder.py\n","      train.py\n","      utils.py\n","    models/\n","      saved_model.pth"],"metadata":{"id":"0Pwvf7RU3gGg"}},{"cell_type":"markdown","source":["### **1/ Get Data**"],"metadata":{"id":"qAr6nsUv32ac"}},{"cell_type":"code","execution_count":9,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Si4Iy2690KjU","executionInfo":{"status":"ok","timestamp":1740769666028,"user_tz":420,"elapsed":557,"user":{"displayName":"Thuan Phat","userId":"17688061894873230324"}},"outputId":"409cf7af-4024-42dd-8bc5-430f81722c1e"},"outputs":[{"output_type":"stream","name":"stdout","text":["data/pizza_steak_sushi directory exists.\n","Downloading pizza, steak, sushi data...\n","Unzipping pizza, steak, sushi data...\n"]}],"source":["import os\n","import requests\n","import zipfile\n","from pathlib import Path\n","\n","# Setup path to data folder\n","data_path = Path(\"data/\")\n","image_path = data_path / \"pizza_steak_sushi\"\n","\n","# If the image folder doesn't exist, download it and prepare it...\n","if image_path.is_dir():\n","    print(f\"{image_path} directory exists.\")\n","else:\n","    print(f\"Did not find {image_path} directory, creating one...\")\n","    image_path.mkdir(parents=True, exist_ok=True)\n","\n","# Download pizza, steak, sushi data\n","with open(data_path / \"pizza_steak_sushi.zip\", \"wb\") as f:\n","    request = requests.get(\"https://github.com/mrdbourke/pytorch-deep-learning/raw/main/data/pizza_steak_sushi.zip\")\n","    print(\"Downloading pizza, steak, sushi data...\")\n","    f.write(request.content)\n","\n","# Unzip pizza, steak, sushi data\n","with zipfile.ZipFile(data_path / \"pizza_steak_sushi.zip\", \"r\") as zip_ref:\n","    print(\"Unzipping pizza, steak, sushi data...\")\n","    zip_ref.extractall(image_path)\n","\n","# Remove zip file\n","os.remove(data_path / \"pizza_steak_sushi.zip\")"]},{"cell_type":"markdown","source":["Now we got these:\n","\n","    data/\n","      pizza_steak_sushi/\n","        train/\n","          pizza/\n","            train_image_01.jpeg\n","            train_image_02.jpeg\n","            ...\n","          steak/\n","          sushi/\n","        test/\n","          pizza/\n","            test_image_01.jpeg\n","            test_image_02.jpeg\n","            ...\n","          steak/\n","          sushi/"],"metadata":{"id":"I2n-7F8j4BdQ"}},{"cell_type":"markdown","source":["### **2/ Create Datasets and DataLoaders**"],"metadata":{"id":"5xuLQG528FZ1"}},{"cell_type":"code","source":["### First make directory 'modular'\n","def create_folder(name: str='modular'):\n","  '''\n","    Create a folder named 'modular' or other names that you need\n","  '''\n","  if not os.path.isdir('modular'):\n","    os.mkdir('modular')\n","    print('Directory has been created!!!')\n","  else:\n","    print('Directory already exists')\n","\n","create_folder()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"QUuhEAJL8XAu","executionInfo":{"status":"ok","timestamp":1740769666080,"user_tz":420,"elapsed":32,"user":{"displayName":"Thuan Phat","userId":"17688061894873230324"}},"outputId":"ed06b360-baf0-47be-8d84-d9c7c8b2926c"},"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["Directory already exists\n"]}]},{"cell_type":"code","source":["%%writefile modular/data_setup.py\n","\n","\"\"\"\n","Contains functionality for creating PyTorch DataLoaders for\n","image classification data.\n","\"\"\"\n","\n","import os\n","from torch.utils.data import Dataset, DataLoader\n","from torchvision import datasets, transforms\n","from typing import List, Tuple\n","\n","NUM_WORKERS = os.cpu_count()\n","\n","def create_dataloaders(train_dir: str=None,\n","                       test_dir: str=None,\n","                       transforms: List[transforms.Compose]=[None, None],\n","                       batch_size: int=None,\n","                       num_workers: int=NUM_WORKERS,\n","                       pin_memory: bool=False) -> Tuple[DataLoader, DataLoader, List[str]]:\n","    \"\"\"Creates training and testing DataLoaders.\n","\n","    Takes in a training directory and testing directory path and turns\n","    them into PyTorch Datasets and then into PyTorch DataLoaders.\n","\n","    Args:\n","      train_dir: Path to training directory.\n","      test_dir: Path to testing directory.\n","      transforms: A list of two transforms: one for training and one for testing data.\n","      batch_size: Number of samples per batch in each of the DataLoaders.\n","      num_workers: An integer for number of workers per DataLoader.\n","\n","    Returns:\n","      A tuple of (train_dataloader, test_dataloader, class_names).\n","      Where class_names is a list of the target classes.\n","    \"\"\"\n","    # Use ImageFolder to create Datasets\n","    train_data = datasets.ImageFolder(train_dir, transform=transforms[0])\n","    test_data = datasets.ImageFolder(test_dir, transform=transforms[1])\n","\n","    # Get class names\n","    class_names = train_data.classes\n","\n","    # Turn into DataLoaders\n","    train_dataloader = DataLoader(train_data,\n","                                  batch_size=batch_size,\n","                                  shuffle=True,\n","                                  num_workers=num_workers,\n","                                  pin_memory=pin_memory)\n","\n","    test_dataloader = DataLoader(test_data,\n","                                 batch_size=batch_size,\n","                                 shuffle=False,\n","                                 num_workers=num_workers,\n","                                 pin_memory=pin_memory)\n","\n","    return train_dataloader, test_dataloader, class_names\n"],"metadata":{"id":"TiJQVg8-38-U","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1740771315224,"user_tz":420,"elapsed":9,"user":{"displayName":"Thuan Phat","userId":"17688061894873230324"}},"outputId":"23e78814-7dff-4ef6-b0bc-8f42bf7e1706"},"execution_count":22,"outputs":[{"output_type":"stream","name":"stdout","text":["Overwriting modular/data_setup.py\n"]}]},{"cell_type":"markdown","source":["### **3/ Build Model**"],"metadata":{"id":"OfLY746lne4b"}},{"cell_type":"code","source":["%%writefile modular/model_builder.py\n","\n","\"\"\"\n","Contains PyTorch model code to instantiate a TinyVGG model.\n","\"\"\"\n","\n","import torch\n","import torch.nn as nn\n","\n","class TinyVGG(nn.Module):\n","  \"\"\"\n","    Creates the TinyVGG model\n","\n","    Args:\n","  input_shape: An integer indicating number of input channels.\n","  hidden_units: An integer indicating number of hidden units between layers.\n","  output_shape: An integer indicating number of output units.\n","  \"\"\"\n","\n","  def __init__(self, input_shape: int, hidden_units: int, output_shape: int) -> None:\n","    super().__init__()\n","    self.conv_block_1 = nn.Sequential(\n","      nn.Conv2d(in_channels=input_shape,\n","                out_channels=hidden_units,\n","                kernel_size=3,\n","                stride=1,\n","                padding=0),\n","      nn.ReLU(),\n","      nn.Conv2d(in_channels=hidden_units,\n","                out_channels=hidden_units,\n","                kernel_size=3,\n","                stride=1,\n","                padding=0),\n","      nn.ReLU(),\n","      nn.MaxPool2d(kernel_size=2,\n","                    stride=2)\n","    )\n","\n","    self.conv_block_2 = nn.Sequential(\n","      nn.Conv2d(hidden_units, hidden_units, kernel_size=3, padding=0),\n","      nn.ReLU(),\n","      nn.Conv2d(hidden_units, hidden_units, kernel_size=3, padding=0),\n","      nn.ReLU(),\n","      nn.MaxPool2d(2)\n","    )\n","\n","    self.classifier = nn.Sequential(\n","      nn.Flatten(),\n","      nn.Linear(in_features=hidden_units*13*13,\n","                out_features=output_shape)\n","    )\n","\n","  def forward(self, x: torch.Tensor):\n","    x = self.conv_block_1(x)\n","    x = self.conv_block_2(x)\n","    x = self.classifier(x)\n","    return x\n","    # return self.classifier(self.block_2(self.block_1(x))) # <- leverage the benefits of operator fusion"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"OuZTPZARneqR","executionInfo":{"status":"ok","timestamp":1740771786989,"user_tz":420,"elapsed":7,"user":{"displayName":"Thuan Phat","userId":"17688061894873230324"}},"outputId":"85c560a0-3059-4d57-fc7b-244944465b28"},"execution_count":31,"outputs":[{"output_type":"stream","name":"stdout","text":["Overwriting modular/model_builder.py\n"]}]},{"cell_type":"markdown","source":["### **4/ Train Step and Test Step**"],"metadata":{"id":"mhVQyQLnooSM"}},{"cell_type":"code","source":["%%writefile modular/engine.py\n","\n","\"\"\"\n","Contains functions for training and testing a PyTorch model.\n","\"\"\"\n","\n","from typing import Dict, List, Tuple\n","import torch\n","from tqdm import tqdm\n","\n","def train_step(model: torch.nn.Module,\n","               dataloader: torch.utils.data.DataLoader,\n","               loss_fn: torch.nn.Module,\n","               optimizer: torch.optim.Optimizer,\n","               device: torch.device='cpu') -> Tuple[float, float]:\n","  \"\"\"\n","    Trains a PyTorch model for a single epoch.\n","\n","    Args:\n","    model: A PyTorch model to be trained.\n","    dataloader: A DataLoader instance for the model to be trained on.\n","    loss_fn: A PyTorch loss function to minimize.\n","    optimizer: A PyTorch optimizer to help minimize the loss function.\n","    device: A target device to compute on (e.g. \"cuda\" or \"cpu\").\n","\n","    Returns:\n","    A tuple of training loss and training accuracy metrics.\n","    In the form (train_loss, train_accuracy).\n","    For example: (0.1112, 0.8743)\n","  \"\"\"\n","\n","  # Put model into train mode\n","  model.train()\n","\n","  # Create variables to store scores\n","  train_loss, train_acc = 0, 0\n","\n","  # Loop through each epoch\n","  for batch, (X, y) in enumerate(dataloader):\n","    X, y = X.to(device), y.to(device)\n","\n","    y_logits = model(X)\n","    loss = loss_fn(y_logits, y)\n","    train_loss += loss.item()\n","\n","    optimizer.zero_grad()\n","    loss.backward()\n","    optimizer.step()\n","\n","    y_pred_label = torch.argmax(torch.softmax(y_logits, dim=1), dim=1)\n","    train_acc += (y_pred_label == y).sum().item()/len(y_pred_label)\n","\n","  # Adjust metrics to get average metrics per batch\n","  train_loss = train_loss / len(dataloader)\n","  train_acc = train_acc / len(dataloader)\n","  return train_loss, train_acc\n","\n","\n","def test_step(model: torch.nn.Module,\n","              dataloader: torch.utils.data.DataLoader,\n","              loss_fn: torch.nn.Module,\n","              device: torch.device='cpu') -> Tuple[float, float]:\n","\n","    \"\"\"\n","    Tests a PyTorch model for a single epoch.\n","\n","    Args:\n","    model: A PyTorch model to be tested.\n","    dataloader: A DataLoader instance for the model to be tested on.\n","    loss_fn: A PyTorch loss function to calculate loss on the test data.\n","    device: A target device to compute on (e.g. \"cuda\" or \"cpu\").\n","\n","    Returns:\n","    A tuple of testing loss and testing accuracy metrics.\n","    In the form (test_loss, test_accuracy).\n","    For example: (0.0223, 0.8985)\n","    \"\"\"\n","\n","    # Put model into mode\n","    model.eval()\n","\n","    # Create variables to store scores\n","    test_loss, test_acc = 0, 0\n","\n","    # Loop through batches\n","    with torch.inference_mode():\n","      for batch, (X, y) in enumerate(dataloader):\n","        X, y = X.to(device), y.to(device)\n","\n","        test_logits = model(X)\n","        loss = loss_fn(test_logits, y)\n","        test_loss += loss.item()\n","\n","        test_pred_labels = torch.argmax(torch.softmax(test_logits, dim=1), dim=1)\n","        test_acc += ((test_pred_labels == y).sum().item()/len(test_pred_labels))\n","\n","    # Adjust metrics\n","    test_loss = test_loss / len(dataloader)\n","    test_acc = test_acc / len(dataloader)\n","    return test_loss, test_acc\n","\n","\n","def train(model: torch.nn.Module,\n","          train_dataloader: torch.utils.data.DataLoader,\n","          test_dataloader: torch.utils.data.DataLoader,\n","          optimizer: torch.optim.Optimizer,\n","          loss_fn: torch.nn.utils,\n","          num_epochs: int=5,\n","          device: torch.device='cpu') -> Dict[str, List[float]]:\n","\n","\n","    \"\"\"\n","      Trains and tests a PyTorch model.\n","\n","      Args:\n","    model: A PyTorch model to be trained and tested.\n","    train_dataloader: A DataLoader instance for the model to be trained on.\n","    test_dataloader: A DataLoader instance for the model to be tested on.\n","    optimizer: A PyTorch optimizer to help minimize the loss function.\n","    loss_fn: A PyTorch loss function to calculate loss on both datasets.\n","    epochs: An integer indicating how many epochs to train for.\n","    device: A target device to compute on (e.g. \"cuda\" or \"cpu\").\n","\n","      Returns:\n","    A dictionary of training and testing loss as well as training and\n","    testing accuracy metrics. Each metric has a value in a list for\n","    each epoch.\n","    In the form: {train_loss: [...],\n","              train_acc: [...],\n","              test_loss: [...],\n","              test_acc: [...]}\n","    For example if training for epochs=2:\n","             {train_loss: [2.0616, 1.0537],\n","              train_acc: [0.3945, 0.3945],\n","              test_loss: [1.2641, 1.5706],\n","              test_acc: [0.3400, 0.2973]}\n","    \"\"\"\n","\n","    # Create a result dictionary\n","    results = {\"train_loss\": [],\n","               \"train_acc\": [],\n","               \"test_loss\": [],\n","               \"test_acc\": []\n","    }\n","\n","    # Loop through each epoch\n","    for epoch in tqdm(range(num_epochs)):\n","      train_loss, train_acc = train_step(model=model,\n","                                          dataloader=train_dataloader,\n","                                          loss_fn=loss_fn,\n","                                          optimizer=optimizer,\n","                                          device=device)\n","\n","      test_loss, test_acc = test_step(model=model,\n","                                      dataloader=test_dataloader,\n","                                      loss_fn=loss_fn,\n","                                      device=device)\n","\n","      # Print out what's happening\n","      print(\n","        f\"Epoch: {epoch+1} | \"\n","        f\"train_loss: {train_loss:.4f} | \"\n","        f\"train_acc: {train_acc:.4f} | \"\n","        f\"test_loss: {test_loss:.4f} | \"\n","        f\"test_acc: {test_acc:.4f}\"\n","      )\n","\n","      # Update results dictionary\n","      results[\"train_loss\"].append(train_loss)\n","      results[\"train_acc\"].append(train_acc)\n","      results[\"test_loss\"].append(test_loss)\n","      results[\"test_acc\"].append(test_acc)\n","\n","    # Return the filled results at the end of the epochs\n","    return results"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"n4XKh-x-nZGD","executionInfo":{"status":"ok","timestamp":1740772065168,"user_tz":420,"elapsed":60,"user":{"displayName":"Thuan Phat","userId":"17688061894873230324"}},"outputId":"061ae716-9745-4113-eadd-74f17f8fe8ee"},"execution_count":40,"outputs":[{"output_type":"stream","name":"stdout","text":["Overwriting modular/engine.py\n"]}]},{"cell_type":"markdown","source":["### **5/ Save Model**"],"metadata":{"id":"ATBquz4n0bjH"}},{"cell_type":"code","source":["%%writefile modular/utils.py\n","\n","\"\"\"\n","Contains various utility functions for PyTorch model training.\n","\"\"\"\n","\n","from pathlib import Path\n","import torch\n","\n","def save_model(model: torch.nn.Module,\n","               model_name: str,\n","               target_dir: str='models'):\n","\n","  \"\"\"\n","    Contains various utility functions for PyTorch model training.\n","\n","    Args:\n","      model: A PyTorch model to save.\n","      model_name: A name for the model file to save.\n","      target_dir: A directory for saving the model to.\n","  \"\"\"\n","\n","  # Create directiory\n","  target_dir_path = Path(target_dir)\n","  target_dir_path.mkdir(parents=True,\n","                        exist_ok=True)\n","\n","  # Create model save path\n","  assert model_name.endswith(\".pth\") or model_name.endswith(\".pt\"), \"model_name should end with '.pt' or '.pth'\"\n","  model_save_path = target_dir_path / model_name\n","\n","  # Save the model state_dict()\n","  print(f\"[INFO] Saving model to: {model_save_path}\")\n","  torch.save(obj=model.state_dict(),\n","            f=model_save_path)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7E1mTvNB0axt","executionInfo":{"status":"ok","timestamp":1740772065174,"user_tz":420,"elapsed":18,"user":{"displayName":"Thuan Phat","userId":"17688061894873230324"}},"outputId":"6c4b7178-5bf0-4530-e553-d3ad1724c50f"},"execution_count":41,"outputs":[{"output_type":"stream","name":"stdout","text":["Overwriting modular/utils.py\n"]}]},{"cell_type":"markdown","source":["### **6/ Start to Train, Evaluate and Save Model**"],"metadata":{"id":"z6Vl-7dq_8x3"}},{"cell_type":"code","source":["%%writefile modular/train_baseline.py\n","\n","import torch\n","import os\n","import data_setup, engine, utils, model_builder\n","from torchvision import transforms\n","\n","# Set hyperparameters\n","NUM_EPOCHS = 10\n","BATCH_SIZE = 32\n","HIDDEN_UNITS = 15\n","LEARNING_RATE = 0.01\n","NUM_WORKERS = os.cpu_count()\n","\n","# Setup directories\n","train_dir = \"data/pizza_steak_sushi/train\"\n","test_dir = \"data/pizza_steak_sushi/test\"\n","\n","# Setup device\n","device = 'cpu'\n","# device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n","\n","# Create data transforms\n","train_transforms = transforms.Compose([\n","  transforms.Resize((64, 64)),\n","  transforms.TrivialAugmentWide(num_magnitude_bins=20),\n","  transforms.ToTensor()\n","])\n","\n","test_transforms = transforms.Compose([\n","  transforms.Resize((64, 64)),\n","  transforms.ToTensor()\n","])\n","\n","# Create DataLoaders\n","train_dataloader, test_dataloader, class_names = data_setup.create_dataloaders(\n","    train_dir=train_dir,\n","    test_dir=test_dir,\n","    transforms=[train_transforms, test_transforms],\n","    batch_size=BATCH_SIZE,\n","    num_workers=NUM_WORKERS,\n","    pin_memory=False\n",")\n","\n","\n","# Create model\n","model = model_builder.TinyVGG(input_shape=3, hidden_units=HIDDEN_UNITS, output_shape=len(class_names)).to(device)\n","\n","# Create loss function and optimizer\n","criterion = torch.nn.CrossEntropyLoss()\n","optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)\n","\n","# Start training with help from engine.py\n","engine.train(model=model,\n","             train_dataloader=train_dataloader,\n","             test_dataloader=test_dataloader,\n","             loss_fn=criterion,\n","             optimizer=optimizer,\n","             num_epochs=NUM_EPOCHS,\n","             device=device)\n","\n","# Save the model with help from utils.py\n","utils.save_model(model=model,\n","                 target_dir=\"models\",\n","                 model_name=\"tinyvgg_model.pth\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Upn6vkh1AD8V","executionInfo":{"status":"ok","timestamp":1740772065177,"user_tz":420,"elapsed":11,"user":{"displayName":"Thuan Phat","userId":"17688061894873230324"}},"outputId":"9e5e1244-3c0a-4f3c-bf5a-a559edecd2d6"},"execution_count":42,"outputs":[{"output_type":"stream","name":"stdout","text":["Overwriting modular/train_baseline.py\n"]}]},{"cell_type":"code","source":["!python modular/train_baseline.py"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"VSD8NiFXE-oz","executionInfo":{"status":"ok","timestamp":1740772092551,"user_tz":420,"elapsed":27378,"user":{"displayName":"Thuan Phat","userId":"17688061894873230324"}},"outputId":"447764ba-5b8f-4a24-f79c-2c04eff0266f"},"execution_count":43,"outputs":[{"output_type":"stream","name":"stdout","text":["  0% 0/10 [00:00<?, ?it/s]Epoch: 1 | train_loss: 1.1531 | train_acc: 0.2734 | test_loss: 1.0939 | test_acc: 0.5417\n"," 10% 1/10 [00:02<00:19,  2.21s/it]Epoch: 2 | train_loss: 1.0951 | train_acc: 0.4297 | test_loss: 1.0951 | test_acc: 0.2604\n"," 20% 2/10 [00:04<00:16,  2.09s/it]Epoch: 3 | train_loss: 1.1047 | train_acc: 0.3047 | test_loss: 1.1009 | test_acc: 0.2604\n"," 30% 3/10 [00:06<00:14,  2.03s/it]Epoch: 4 | train_loss: 1.0910 | train_acc: 0.4258 | test_loss: 1.1079 | test_acc: 0.2604\n"," 40% 4/10 [00:09<00:15,  2.56s/it]Epoch: 5 | train_loss: 1.1049 | train_acc: 0.3047 | test_loss: 1.1123 | test_acc: 0.2604\n"," 50% 5/10 [00:11<00:11,  2.37s/it]Epoch: 6 | train_loss: 1.1035 | train_acc: 0.3047 | test_loss: 1.1073 | test_acc: 0.2604\n"," 60% 6/10 [00:13<00:08,  2.25s/it]Epoch: 7 | train_loss: 1.1002 | train_acc: 0.3047 | test_loss: 1.0991 | test_acc: 0.2604\n"," 70% 7/10 [00:15<00:06,  2.17s/it]Epoch: 8 | train_loss: 1.1061 | train_acc: 0.3047 | test_loss: 1.0917 | test_acc: 0.2604\n"," 80% 8/10 [00:17<00:04,  2.14s/it]Epoch: 9 | train_loss: 1.0970 | train_acc: 0.4258 | test_loss: 1.0932 | test_acc: 0.2604\n"," 90% 9/10 [00:19<00:02,  2.10s/it]Epoch: 10 | train_loss: 1.1027 | train_acc: 0.3047 | test_loss: 1.0974 | test_acc: 0.2604\n","100% 10/10 [00:23<00:00,  2.32s/it]\n","[INFO] Saving model to: models/tinyvgg_model.pth\n"]}]},{"cell_type":"markdown","source":["### **7/ Load Saved Model**"],"metadata":{"id":"zZs62aB2GoNi"}},{"cell_type":"code","source":["import torch\n","import torchinfo\n","from modular import model_builder\n","\n","saved_model = model_builder.TinyVGG(input_shape=3, hidden_units=15, output_shape=3).to('cpu')\n","saved_model.load_state_dict(torch.load('models/tinyvgg_model.pth'))\n","torchinfo.summary(saved_model, (1, 3, 64, 64))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":399},"id":"yKvY6E_wGnkX","executionInfo":{"status":"error","timestamp":1740772328685,"user_tz":420,"elapsed":38,"user":{"displayName":"Thuan Phat","userId":"17688061894873230324"}},"outputId":"5804a0af-4989-4488-9b85-118e775790e1"},"execution_count":47,"outputs":[{"output_type":"error","ename":"ModuleNotFoundError","evalue":"No module named 'torchinfo'","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)","\u001b[0;32m<ipython-input-47-b7024503164e>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtorchinfo\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mmodular\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmodel_builder\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0msaved_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_builder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTinyVGG\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_units\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m15\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_shape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'cpu'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'torchinfo'","","\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"],"errorDetails":{"actions":[{"action":"open_url","actionText":"Open Examples","url":"/notebooks/snippets/importing_libraries.ipynb"}]}}]}]}